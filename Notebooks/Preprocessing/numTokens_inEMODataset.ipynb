{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets  # datasets es una libreria para cargar y procesar conjuntos de datos de NLP\n",
    "import pandas as pd # pandas es una libreria para an√°lisis de datos\n",
    "import transformers # transformers es de hugingface\n",
    "from transformers import LlamaTokenizer # tokenizers es de hugingface\n",
    "from huggingface_hub import login # huggingface_hub es de hugingface\n",
    "from time import sleep, time\n",
    "import nltk\n",
    "ntlk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\bruno_k6bfbrq\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "access_token = \"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\"\n",
    "login(token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= datasets.load_dataset(\"BrunoGR/emotional_response_spanish_dataset\",cache_dir=\"dtaset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['index', 'input', 'output', 'Prompt_sp', 'Prompt_mix', 'Prompt_en'],\n",
       "        num_rows: 1320\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['index', 'input', 'output', 'Prompt_sp', 'Prompt_mix', 'Prompt_en'],\n",
       "        num_rows: 41910\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['index', 'input', 'output', 'Prompt_sp', 'Prompt_mix', 'Prompt_en'],\n",
       "        num_rows: 2220\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(data['train'])\n",
    "eval_df = pd.DataFrame(data['validation'])\n",
    "test_df = pd.DataFrame(data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =   LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(dataframe):\n",
    "    num_tokens = [len(tokenizer.encode(x)) for x in dataframe['Prompt_en']]\n",
    "    count=[len(nltk.word_tokenize(x)) for x in dataframe['Prompt_en']]\n",
    "    nt=sum(num_tokens)\n",
    "    ct=sum(count)\n",
    "    return nt,ct\n",
    "def median_tokens(dataframe):\n",
    "    count_input = [len(tokenizer.encode(x)) for x in dataframe['input']]\n",
    "    count_output = [len(tokenizer.encode(x)) for x in dataframe['output']]\n",
    "    median_input = sum(count_input)/len(count_input)\n",
    "    median_output = sum(count_output)/len(count_output)\n",
    "    return median_input,median_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in train dataset: a) 10768855 b) 8694022 median_input: 45.37933667382486 median_output: 66.55688379861608\n",
      "Number of tokens in eval dataset: a) 638178 b) 504585 median_input: 68.63423423423423 median_output: 73.80495495495495\n",
      "Number of tokens in test dataset: a) 387770 b) 305303  median_input: 71.38181818181818 median_output: 77.35303030303031\n"
     ]
    }
   ],
   "source": [
    "midTrain_input,midTrain_output=median_tokens(train_df)\n",
    "ntTrain,cttrain=count_tokens(train_df)\n",
    "ntEval,ctEval=count_tokens(eval_df)\n",
    "midEval_input,midEval_output=median_tokens(eval_df)\n",
    "ntTest,ctTest=count_tokens(test_df)\n",
    "midTest_input,midTest_output=median_tokens(test_df)\n",
    "print( f\"Number of tokens in train dataset: a) {ntTrain} b) {cttrain} median_input: {midTrain_input} median_output: {midTrain_output}\")\n",
    "print( f\"Number of tokens in eval dataset: a) {ntEval} b) {ctEval} median_input: {midEval_input} median_output: {midEval_output}\")\n",
    "print( f\"Number of tokens in test dataset: a) {ntTest} b) {ctTest}  median_input: {midTest_input} median_output: {midTest_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
